
# ğŸš€ RAG API with Deterministic CI/CD Pipeline

## ğŸ“Œ Overview

This project implements a Retrieval-Augmented Generation (RAG) API with automated CI/CD validation using GitHub Actions.

It goes beyond basic RAG implementation by solving a critical real-world problem:

> LLM outputs are non-deterministic, making automated testing unreliable.

To address this, I implemented **Mock LLM mode**, enabling deterministic retrieval testing inside CI pipelines.

This mirrors production-grade AI system design.

---

## ğŸ›  Tech Stack

* API Framework: FastAPI
* Vector Database: ChromaDB
* LLM: Ollama (TinyLlama)
* CI/CD: GitHub Actions
* Testing: Semantic validation script
* Embeddings: Custom embed pipeline

---

## ğŸ— Architecture

```
User Query
    â†“
FastAPI
    â†“
ChromaDB (Vector Search)
    â†“
Retrieved Context
    â†“
Production Mode â†’ Ollama (LLM)
Mock Mode â†’ Return Context Directly
```

---

# ğŸ” The Core Problem: LLM Non-Determinism

To test retrieval quality, I intentionally removed the keyword **â€œorchestrationâ€** from the knowledge base.

After rebuilding embeddings and querying the API multiple times:

* Sometimes the answer included â€œorchestrationâ€
* Sometimes it did not
* The output changed for the same query

Why?

Because the LLM was trained associating:

```
Kubernetes â†” Orchestration
```

Even though the knowledge base no longer contained the word.

This exposed a serious issue:

> Automated tests become unreliable when generation is probabilistic.

---

# ğŸ§  Why This Matters

In CI/CD:

* Tests must be deterministic
* Builds must be reliable
* Failures must reflect real issues

If LLM output varies randomly:

* Tests pass when they shouldnâ€™t
* Tests fail when nothing changed
* Engineers lose trust in CI
* Real regressions get ignored

This is unacceptable in production systems.

---

# âœ… The Solution: Mock LLM Mode

I implemented an environment-variable-driven mode:

```python
USE_MOCK_LLM = os.getenv("USE_MOCK_LLM", "0") == "1"
```

### Production Mode

* Uses Ollama for natural language responses.

### Mock Mode

* Returns retrieved context directly.
* Skips LLM generation.
* Produces deterministic output.

---

## ğŸ¯ Why Mock Mode is Critical

* Deterministic CI validation
* No dependency on Ollama in CI
* Faster test execution
* Retrieval-focused testing
* Production-safe pipelines

This separates:

**Retrieval Quality** from
**LLM Generation Variability**

---

# ğŸ§ª Semantic Testing Strategy

Instead of testing exact responses, I implemented:

* Meaning-focused validation
* Required keyword checks
* Retrieval correctness testing

Example:

```python
assert "orchestration" in response
assert "container" in response
```

This ensures knowledge quality, not phrasing style.

---

# âš™ï¸ CI/CD Automation (GitHub Actions)

Workflow triggers when:

* k8s.txt changes
* app.py changes
* embed.py changes

Pipeline Steps:

1. Checkout code
2. Install dependencies
3. Rebuild embeddings
4. Start API in Mock Mode
5. Run semantic tests
6. Pass/Fail build

If keywords are missing:

âŒ Build fails
âœ… Deployment blocked

---

# ğŸ”´ Demonstration of CI Catching Data Degradation

When I pushed the modified `k8s.txt` (missing "orchestration"):

* CI rebuilt embeddings
* Mock mode returned deterministic context
* Semantic test failed
* GitHub Actions blocked the build

This prevented degraded knowledge from reaching production.
# Note
 The Ci workflow completed successfully while the k8s.txt files contains all keywords. 

---

# ğŸš€ What This Project Demonstrates

* RAG system implementation
* Embedding lifecycle management
* LLM non-determinism handling
* Deterministic CI design
* Mock-based testing strategy
* Production-grade AI validation
* GitHub Actions automation
* Separation of concerns in AI systems

---

# ğŸ§  Engineering Insight

LLMs are probabilistic systems.

CI pipelines are deterministic systems.

Bridging them requires architectural separation between:

* Retrieval validation
* Generation behavior

Mock mode enables that separation.

This is how real companies maintain AI system quality at scale.

---

# ğŸ“ˆ Future Improvements

* Multi-document knowledge base


---

# ğŸ¯ Final Takeaway

This project evolved from a simple RAG API into a fully automated, production-aware AI system with deterministic validation.

It reflects how modern AI engineering teams:

* Protect data quality
* Enforce CI trust
* Separate retrieval from generation
* Prevent silent knowledge degradation



